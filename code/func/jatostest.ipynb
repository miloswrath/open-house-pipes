{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "def get_met(tease):\n",
    "\n",
    "    \n",
    "\n",
    "    proxies = {\n",
    "    'http': f'http:zjgilliam:{tease}@proxy.divms.uiowa.edu:8888',\n",
    "    'https': f'http://zjgilliam:{tease}@proxy.divms.uiowa.edu:8888',\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    url = 'https://jatos.psychology.uiowa.edu/jatos/api/v1/results/metadata'\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'Authorization': 'Bearer jap_5ThOJ14yf7z1EPEUpAoZYMWoETZcmJk305719',\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    data = {\n",
    "        'studyIds': [999]\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data, #proxies=proxies\n",
    "    )\n",
    "\n",
    "    # If you want to print the response\n",
    "    print(response.status_code)\n",
    "    print(response.json())\n",
    "    response_json = response.json()\n",
    "\n",
    "    response = response_json\n",
    "\n",
    "    # Get the current timestamp\n",
    "    current_time = datetime.now().timestamp() * 1000  # Convert to milliseconds\n",
    "    one_minute_ago = current_time - (60 * 60 * 24 * 7 * 1000)\n",
    "    # Initialize an empty list to store study result IDs\n",
    "    study_result_ids = []\n",
    "\n",
    "    # Iterate through the data to check conditions and collect study result IDs\n",
    "    for study in response['data']:\n",
    "        for study_result in study['studyResults']:\n",
    "            if study_result['studyState'] == 'FINISHED' and study_result['endDate'] >= one_minute_ago:\n",
    "                study_result_ids.append(study_result['id'])\n",
    "                break  # No need to check other component results for this study result\n",
    "\n",
    "    # Print the list of study result IDs\n",
    "    print(study_result_ids)\n",
    "\n",
    "    if len(study_result_ids) == 0:\n",
    "        print(\"No study results found.\")\n",
    "        exit()\n",
    "    \n",
    "    return study_result_ids\n",
    "\n",
    "def get_data(study_result_ids, tease):\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    proxies = {\n",
    "    'http': f'http://zjgilliam:{tease}@proxy.divms.uiowa.edu:8888',\n",
    "    'https': f'http://zjgilliam:{tease}@proxy.divms.uiowa.edu:8888',\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'accept': 'application/octet-stream',\n",
    "        'Authorization': 'Bearer jap_5ThOJ14yf7z1EPEUpAoZYMWoETZcmJk305719',\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    # Get the data for each study result\n",
    "    datas = {\n",
    "        'studyIds': [999],\n",
    "        'studyResultIds': study_result_ids\n",
    "    }\n",
    "\n",
    "    url = 'https://jatos.psychology.uiowa.edu/jatos/api/v1/results/data'\n",
    "    response = requests.post(url, headers=headers, json=datas, #proxies=proxies\n",
    "    )\n",
    "    # Debugging information\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "\n",
    "\n",
    "    # Save the unzip file and save .txt file to the current directory\n",
    "    if response.status_code == 200:\n",
    "        jrzip_file = 'response.jrzip'\n",
    "        with open(jrzip_file, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded file: {jrzip_file}\")\n",
    "\n",
    "        # Verify if the file is a valid zip file\n",
    "        if zipfile.is_zipfile(jrzip_file):\n",
    "            print(\"The file is a valid zip file.\")\n",
    "\n",
    "            # Create a new zip file with only the desired files\n",
    "            filtered_jrzip_file = 'filtered_response.jrzip'\n",
    "            with zipfile.ZipFile(jrzip_file, 'r') as zip_ref:\n",
    "                with zipfile.ZipFile(filtered_jrzip_file, 'w') as filtered_zip_ref:\n",
    "                    for zip_info in zip_ref.infolist():\n",
    "                        # Check if the filename contains any of the study_result_ids\n",
    "                        if any(str(study_result_id) in zip_info.filename for study_result_id in study_result_ids):\n",
    "                            filtered_zip_ref.writestr(zip_info, zip_ref.read(zip_info.filename))\n",
    "            print(f\"Filtered zip file created: {filtered_jrzip_file}\")\n",
    "\n",
    "            # Extract the filtered zip file\n",
    "            with zipfile.ZipFile(filtered_jrzip_file, 'r') as zip_ref:\n",
    "                zip_ref.extractall('./../../data/raw')\n",
    "            print(f\"Unzipped file: {filtered_jrzip_file}\")\n",
    "\n",
    "            # Optionally, remove the original and filtered zip files after extraction\n",
    "            os.remove(jrzip_file)\n",
    "            os.remove(filtered_jrzip_file)\n",
    "\n",
    "            # Walk through the directory and find all .txt files, save paths to a list\n",
    "            txt_files = []\n",
    "            for root, dirs, files in os.walk(\"./../../data/raw\"):\n",
    "                for file in files:\n",
    "                    if file.endswith(\".txt\"):\n",
    "                        txt_files.append(os.path.join(root, file))\n",
    "            print(f\"Found {len(txt_files)} .txt files.\")\n",
    "            #move the text file to the data folder\n",
    "\n",
    "        else:\n",
    "            print(\"The file is not a valid zip file.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve or save the file.\")\n",
    "        print(f\"Response Text: {response.text}\")\n",
    "\n",
    "    return txt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_run_dir(sub):\n",
    "    base_dir = f'./../../data/{sub}/processed'\n",
    "    i = 1\n",
    "    while os.path.exists(os.path.join(base_dir, f'run-{i}')):\n",
    "        i += 1\n",
    "    return os.path.join(base_dir, f'run-{i}')\n",
    "\n",
    "\n",
    "\n",
    "def convert_beh(txt_files):\n",
    "\n",
    "            \n",
    "    dic = {}\n",
    "    for idx, b in enumerate(txt_files, start=1):\n",
    "        tweets = []\n",
    "        with open(b, 'r') as file:\n",
    "            for line in file:\n",
    "                tweets.append(json.loads(line))\n",
    "        dic[idx] = pd.json_normalize(tweets, 'data')\n",
    "\n",
    "    print(\"Data dictionaries created.\")\n",
    "\n",
    "    all_paths = []\n",
    "    for i in dic:\n",
    "        df = dic[i]\n",
    "        for sub in np.unique(df['multichar_response']):\n",
    "            print(f\"Processing subject: {sub}\")\n",
    "            # Filter data for this subject\n",
    "            sub_df = df[df['multichar_response'] == sub]\n",
    "\n",
    "            # Get next run directory\n",
    "            run_dir = get_next_run_dir(sub)\n",
    "            os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "            # Build the CSV file path\n",
    "            csv_filename = f\"{sub}.csv\"\n",
    "            csv_path = os.path.join(run_dir, csv_filename)\n",
    "\n",
    "            # Save CSV\n",
    "            sub_df.to_csv(csv_path, index=False)\n",
    "            print(f\"Saved {csv_path}\")\n",
    "\n",
    "            all_paths.append(csv_path)\n",
    "\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_txt(txt_files):\n",
    "    dic = {}\n",
    "    for file_path in txt_files:\n",
    "        tweets = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Read text file and append each line as a JSON object to tweets\n",
    "            for line in file:\n",
    "                tweets.append(json.loads(line))\n",
    "        dic[file_path] = pd.json_normalize(tweets, 'data')\n",
    "\n",
    "    for file_path, df in dic.items():\n",
    "        for sub in np.unique(df['multichar_response']):\n",
    "            print(sub)\n",
    "            target_dir = f'./../../data/{sub}/raw'\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "            # Save the DataFrame to a text file in the target directory\n",
    "            output_file = os.path.join(target_dir, os.path.basename(file_path))\n",
    "            with open(output_file, 'w') as f:\n",
    "                f.write(df.to_string(index=False))\n",
    "            print(f\"Saved {output_file} to {target_dir}\")\n",
    "        os.remove(file_path)\n",
    "        print(f\"Removed {file_path}\")\n",
    "\n",
    "    # Move the directory removal outside the loop\n",
    "    for root, dirs, files in os.walk('./../../data/raw'):\n",
    "        for d in dirs:\n",
    "            shutil.rmtree(os.path.join(root, d))\n",
    "    # Optionally, remove the raw directory itself\n",
    "    os.rmdir('./../../data/raw')\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'apiVersion': '1.0.1', 'data': [{'studyId': 999, 'studyUuid': '93008b03-4ff3-4190-9db1-d71fb2c74af2', 'studyTitle': 'Pipe_Comparison ', 'studyResults': [{'id': 12256, 'uuid': 'b1fb7f82-e7b5-4099-aa83-15ba25d3dae8', 'studyCode': 'm752BMNbAjG', 'startDate': 1731022807000, 'endDate': 1731022880000, 'duration': '00:01:13', 'lastSeenDate': 1731022808000, 'studyState': 'FINISHED', 'workerId': 5187, 'workerType': 'Jatos', 'batchId': 1036, 'batchUuid': '784275e0-000b-4cd2-93f2-bd306b55dbcb', 'batchTitle': 'Default', 'groupId': None, 'componentResults': [{'id': 11864, 'componentId': 1000, 'componentUuid': 'b7583473-ed28-4dec-8175-f03157901667', 'startDate': 1731022808000, 'endDate': 1731022880000, 'duration': '00:01:12', 'componentState': 'FINISHED', 'path': '/study_result_12256/comp-result_11864', 'data': {'size': 38773, 'sizeHumanReadable': '38.8 kB'}, 'files': []}]}, {'id': 12258, 'uuid': '2973436b-3e6e-4146-bdaa-99b0dffc5a43', 'studyCode': 'cYe0OluHqvF', 'startDate': 1731024546000, 'endDate': 1731024656000, 'duration': '00:01:50', 'lastSeenDate': 1731024547000, 'studyState': 'FINISHED', 'workerId': 8740, 'workerType': 'PersonalMultiple', 'batchId': 1036, 'batchUuid': '784275e0-000b-4cd2-93f2-bd306b55dbcb', 'batchTitle': 'Default', 'groupId': None, 'componentResults': [{'id': 11866, 'componentId': 1000, 'componentUuid': 'b7583473-ed28-4dec-8175-f03157901667', 'startDate': 1731024546000, 'endDate': 1731024656000, 'duration': '00:01:50', 'componentState': 'FINISHED', 'path': '/study_result_12258/comp-result_11866', 'data': {'size': 25555, 'sizeHumanReadable': '25.6 kB'}, 'files': []}]}, {'id': 12261, 'uuid': '66d58758-23f3-4982-af3a-59cfb72f4a5a', 'studyCode': 'cYe0OluHqvF', 'startDate': 1731033918000, 'endDate': 1731034194000, 'duration': '00:04:36', 'lastSeenDate': 1731034159000, 'studyState': 'FINISHED', 'workerId': 8740, 'workerType': 'PersonalMultiple', 'batchId': 1036, 'batchUuid': '784275e0-000b-4cd2-93f2-bd306b55dbcb', 'batchTitle': 'Default', 'groupId': None, 'componentResults': [{'id': 11869, 'componentId': 1000, 'componentUuid': 'b7583473-ed28-4dec-8175-f03157901667', 'startDate': 1731033918000, 'endDate': 1731034194000, 'duration': '00:04:36', 'componentState': 'FINISHED', 'path': '/study_result_12261/comp-result_11869', 'data': {'size': 20168, 'sizeHumanReadable': '20.2 kB'}, 'files': []}]}, {'id': 12262, 'uuid': 'd1fac74d-93f7-4e3c-adea-86fc4b8a26a1', 'studyCode': 'cYe0OluHqvF', 'startDate': 1731034204000, 'endDate': 1731034281000, 'duration': '00:01:17', 'lastSeenDate': 1731034205000, 'studyState': 'FINISHED', 'workerId': 8740, 'workerType': 'PersonalMultiple', 'batchId': 1036, 'batchUuid': '784275e0-000b-4cd2-93f2-bd306b55dbcb', 'batchTitle': 'Default', 'groupId': None, 'componentResults': [{'id': 11870, 'componentId': 1000, 'componentUuid': 'b7583473-ed28-4dec-8175-f03157901667', 'startDate': 1731034204000, 'endDate': 1731034281000, 'duration': '00:01:17', 'componentState': 'FINISHED', 'path': '/study_result_12262/comp-result_11870', 'data': {'size': 38301, 'sizeHumanReadable': '38.3 kB'}, 'files': []}]}, {'id': 12264, 'uuid': 'f2a926c2-d231-4b4f-a469-dba2989a4d3c', 'studyCode': 'cYe0OluHqvF', 'startDate': 1731035178000, 'endDate': 1731035329000, 'duration': '00:02:31', 'lastSeenDate': 1731035299000, 'studyState': 'FINISHED', 'workerId': 8740, 'workerType': 'PersonalMultiple', 'batchId': 1036, 'batchUuid': '784275e0-000b-4cd2-93f2-bd306b55dbcb', 'batchTitle': 'Default', 'groupId': None, 'componentResults': [{'id': 11872, 'componentId': 1000, 'componentUuid': 'b7583473-ed28-4dec-8175-f03157901667', 'startDate': 1731035178000, 'endDate': 1731035329000, 'duration': '00:02:31', 'componentState': 'FINISHED', 'path': '/study_result_12264/comp-result_11872', 'data': {'size': 38457, 'sizeHumanReadable': '38.5 kB'}, 'files': []}]}, {'id': 12266, 'uuid': '936edd3b-65bb-41c6-98ef-bb3a73faabe1', 'studyCode': 'cYe0OluHqvF', 'startDate': 1731074128000, 'endDate': 1731074246000, 'duration': '00:01:58', 'lastSeenDate': 1731074129000, 'studyState': 'FINISHED', 'workerId': 8740, 'workerType': 'PersonalMultiple', 'batchId': 1036, 'batchUuid': '784275e0-000b-4cd2-93f2-bd306b55dbcb', 'batchTitle': 'Default', 'groupId': None, 'componentResults': [{'id': 11874, 'componentId': 1000, 'componentUuid': 'b7583473-ed28-4dec-8175-f03157901667', 'startDate': 1731074128000, 'endDate': 1731074246000, 'duration': '00:01:58', 'componentState': 'FINISHED', 'path': '/study_result_12266/comp-result_11874', 'data': {'size': 27422, 'sizeHumanReadable': '27.4 kB'}, 'files': []}]}, {'id': 12267, 'uuid': '1ff82458-36cc-4ce7-ab44-6b6629261117', 'studyCode': 'cYe0OluHqvF', 'startDate': 1731077093000, 'endDate': 1731077202000, 'duration': '00:01:49', 'lastSeenDate': 1731077093000, 'studyState': 'FINISHED', 'workerId': 8740, 'workerType': 'PersonalMultiple', 'batchId': 1036, 'batchUuid': '784275e0-000b-4cd2-93f2-bd306b55dbcb', 'batchTitle': 'Default', 'groupId': None, 'componentResults': [{'id': 11875, 'componentId': 1000, 'componentUuid': 'b7583473-ed28-4dec-8175-f03157901667', 'startDate': 1731077093000, 'endDate': 1731077202000, 'duration': '00:01:49', 'componentState': 'FINISHED', 'path': '/study_result_12267/comp-result_11875', 'data': {'size': 38345, 'sizeHumanReadable': '38.3 kB'}, 'files': []}]}, {'id': 12269, 'uuid': '0a911895-ee6f-417b-81e1-9cba215ffb07', 'studyCode': 'cYe0OluHqvF', 'startDate': 1731085278000, 'endDate': 1731085316000, 'duration': '00:00:38', 'lastSeenDate': 1731085278000, 'studyState': 'FAIL', 'message': 'Experiment aborted by user', 'workerId': 8740, 'workerType': 'PersonalMultiple', 'batchId': 1036, 'batchUuid': '784275e0-000b-4cd2-93f2-bd306b55dbcb', 'batchTitle': 'Default', 'groupId': None, 'componentResults': [{'id': 11877, 'componentId': 1000, 'componentUuid': 'b7583473-ed28-4dec-8175-f03157901667', 'startDate': 1731085278000, 'endDate': 1731085316000, 'duration': '00:00:38', 'componentState': 'FAIL', 'path': '/study_result_12269/comp-result_11877', 'data': {'size': 983, 'sizeHumanReadable': '983 B'}, 'files': []}]}, {'id': 12270, 'uuid': 'ab0b4763-32b0-483f-b1a4-60ee3ffa67a9', 'studyCode': 'cYe0OluHqvF', 'startDate': 1731085322000, 'endDate': 1731085423000, 'duration': '00:01:41', 'lastSeenDate': 1731085322000, 'studyState': 'FINISHED', 'workerId': 8740, 'workerType': 'PersonalMultiple', 'batchId': 1036, 'batchUuid': '784275e0-000b-4cd2-93f2-bd306b55dbcb', 'batchTitle': 'Default', 'groupId': None, 'componentResults': [{'id': 11878, 'componentId': 1000, 'componentUuid': 'b7583473-ed28-4dec-8175-f03157901667', 'startDate': 1731085322000, 'endDate': 1731085423000, 'duration': '00:01:41', 'componentState': 'FINISHED', 'path': '/study_result_12270/comp-result_11878', 'data': {'size': 37094, 'sizeHumanReadable': '37.1 kB'}, 'files': []}]}]}]}\n",
      "[12256]\n",
      "Status Code: 200\n",
      "Downloaded file: response.jrzip\n",
      "The file is a valid zip file.\n",
      "Filtered zip file created: filtered_response.jrzip\n",
      "Unzipped file: filtered_response.jrzip\n",
      "Found 1 .txt files.\n",
      "Data dictionaries created.\n",
      "Processing subject: cashmoney\n",
      "Saved ./../../data/cashmoney/processed/run-1/cashmoney.csv\n",
      "cashmoney\n",
      "Saved ./../../data/cashmoney/raw/data.txt to ./../../data/cashmoney/raw\n",
      "Removed ./../../data/raw/study_result_12256/comp-result_11864/data.txt\n"
     ]
    }
   ],
   "source": [
    "text_files = get_data(get_met('zjgill'), 'zjgilliam')\n",
    "convert_beh(text_files)\n",
    "move_txt(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.DataFrame(columns=['sub_name', 'composite', 'rank'])\n",
    "csv.to_csv('./../../data/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sub_name</th>\n",
       "      <th>composite</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, sub_name, composite, rank]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./../../data/results.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0', 'index'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#remove Unnamed: 0, composite_x and composite_y\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/pandas/core/frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4816\u001b[0m ):\n\u001b[1;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0', 'index'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#remove Unnamed: 0, composite_x and composite_y\n",
    "\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_name</th>\n",
       "      <th>composite</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sub_name, composite, rank]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./../../data/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
